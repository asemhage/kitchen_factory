#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù†Ø¸Ø§Ù… Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ø£Ø±Ø´ÙØ© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025-10-14
Ø§Ù„Ù‡Ø¯Ù: ØªÙ†ÙÙŠØ° Ø£Ø±Ø´ÙØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ù„Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø¤Ù‡Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¬Ø¯ÙˆÙ„Ø© Ø²Ù…Ù†ÙŠØ©

Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:
- Ø¬Ø¯ÙˆÙ„Ø© Ø£Ø±Ø´ÙØ© ÙŠÙˆÙ…ÙŠØ©ØŒ Ø£Ø³Ø¨ÙˆØ¹ÙŠØ©ØŒ Ø´Ù‡Ø±ÙŠØ©
- Ù…Ø±Ø§Ù‚Ø¨Ø© ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
- Ø¥Ø´Ø¹Ø§Ø±Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ù„Ù„Ù…Ø¯ÙŠØ±ÙŠÙ†
- Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙØµÙ„Ø© Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª
- Ù†Ø¸Ø§Ù… Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
"""

import schedule
import time
import threading
import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Any
import json
import sqlite3
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('archive_scheduler.log'),
        logging.StreamHandler()
    ]
)

class ArchiveScheduler:
    """Ù†Ø¸Ø§Ù… Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ø£Ø±Ø´ÙØ© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©"""
    
    def __init__(self, app=None, db_path='instance/kitchen_factory.db'):
        self.app = app
        self.db_path = db_path
        self.logger = logging.getLogger('ArchiveScheduler')
        self.running = False
        self.scheduler_thread = None
        self.stats = {
            'total_runs': 0,
            'successful_runs': 0,
            'failed_runs': 0,
            'last_run': None,
            'next_run': None,
            'total_archived': 0
        }
    
    def start(self):
        """Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©"""
        if self.running:
            self.logger.warning("Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø© ÙŠØ¹Ù…Ù„ Ø¨Ø§Ù„ÙØ¹Ù„")
            return
        
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if not os.path.exists(self.db_path):
                self.logger.error(f"Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {self.db_path}")
                return
            
            self.running = True
            self.setup_schedules()
            
            # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„
            self.scheduler_thread = threading.Thread(target=self._run_scheduler, daemon=True)
            self.scheduler_thread.start()
            
            self.logger.info("âœ… ØªÙ… Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ù†Ø¸Ø§Ù… Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ø£Ø±Ø´ÙØ©")
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…: {str(e)}")
            self.running = False
    
    def stop(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©"""
        self.running = False
        schedule.clear()
        self.logger.info("â¹ï¸ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ù†Ø¸Ø§Ù… Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ø£Ø±Ø´ÙØ©")
    
    def setup_schedules(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ù„Ø£Ø±Ø´ÙØ©"""
        
        try:
            # Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ø£Ø±Ø´ÙØ© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© - 2:00 ØµØ¨Ø§Ø­Ø§Ù‹
            schedule.every().day.at("02:00").do(self.daily_archive_maintenance)
            
            # Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© - Ø§Ù„Ø£Ø­Ø¯ 1:00 ØµØ¨Ø§Ø­Ø§Ù‹
            schedule.every().sunday.at("01:00").do(self.weekly_maintenance)
            
            # Ø¬Ø¯ÙˆÙ„Ø© ÙØ­Øµ Ø§Ù„Ù†Ø¸Ø§Ù… ÙƒÙ„ Ø³Ø§Ø¹Ø©
            schedule.every().hour.do(self.hourly_health_check)
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙƒÙ„ 6 Ø³Ø§Ø¹Ø§Øª
            schedule.every(6).hours.do(self.update_statistics)
            
            # ÙØ­Øµ Ø³Ø±ÙŠØ¹ ÙƒÙ„ 30 Ø¯Ù‚ÙŠÙ‚Ø©
            schedule.every(30).minutes.do(self.quick_health_check)
            
            self.logger.info("âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø£Ø±Ø´ÙØ© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©")
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„: {str(e)}")
    
    def _run_scheduler(self):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„"""
        self.logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø­Ù„Ù‚Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©")
        
        while self.running:
            try:
                schedule.run_pending()
                time.sleep(60)  # ÙØ­Øµ ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ø©
                
            except Exception as e:
                self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ù„Ù‚Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©: {str(e)}")
                time.sleep(300)  # Ø§Ù†ØªØ¸Ø§Ø± 5 Ø¯Ù‚Ø§Ø¦Ù‚ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
        
        self.logger.info("â¹ï¸ Ø§Ù†ØªÙ‡Øª Ø­Ù„Ù‚Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©")
    
    def daily_archive_maintenance(self):
        """ØµÙŠØ§Ù†Ø© Ø§Ù„Ø£Ø±Ø´ÙØ© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©"""
        
        self.logger.info("ğŸŒ… Ø¨Ø¯Ø¡ Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ù„Ù„Ø£Ø±Ø´ÙØ©")
        start_time = datetime.now(timezone.utc)
        
        try:
            # ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…
            if not self._is_archive_system_enabled():
                self.logger.info("Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø±Ø´ÙØ© Ù…Ø¹Ø·Ù„ - ØªØ®Ø·ÙŠ Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©")
                return
            
            results = {
                'orders_archived': 0,
                'technician_dues_archived': 0,
                'audit_logs_archived': 0,
                'total_archived': 0,
                'errors': []
            }
            
            # Ø£Ø±Ø´ÙØ© Ø§Ù„Ø·Ù„Ø¨ÙŠØ§Øª Ø§Ù„Ù…Ø¤Ù‡Ù„Ø©
            try:
                orders_result = self._archive_eligible_orders()
                results['orders_archived'] = orders_result.get('successful_count', 0)
                results['total_archived'] += results['orders_archived']
                
                if orders_result.get('failed_count', 0) > 0:
                    results['errors'].append(f"ÙØ´Ù„ Ø£Ø±Ø´ÙØ© {orders_result['failed_count']} Ø·Ù„Ø¨ÙŠØ©")
                
            except Exception as e:
                error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø£Ø±Ø´ÙØ© Ø§Ù„Ø·Ù„Ø¨ÙŠØ§Øª: {str(e)}"
                results['errors'].append(error_msg)
                self.logger.error(error_msg)
            
            # Ø£Ø±Ø´ÙØ© Ù…Ø³ØªØ­Ù‚Ø§Øª Ø§Ù„ÙÙ†ÙŠÙŠÙ† Ø§Ù„Ù…Ø¤Ù‡Ù„Ø©
            try:
                dues_result = self._archive_eligible_technician_dues()
                results['technician_dues_archived'] = dues_result.get('successful_count', 0)
                results['total_archived'] += results['technician_dues_archived']
                
                if dues_result.get('failed_count', 0) > 0:
                    results['errors'].append(f"ÙØ´Ù„ Ø£Ø±Ø´ÙØ© {dues_result['failed_count']} Ù…Ø³ØªØ­Ù‚")
                
            except Exception as e:
                error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø£Ø±Ø´ÙØ© Ù…Ø³ØªØ­Ù‚Ø§Øª Ø§Ù„ÙÙ†ÙŠÙŠÙ†: {str(e)}"
                results['errors'].append(error_msg)
                self.logger.error(error_msg)
            
            # Ø£Ø±Ø´ÙØ© Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ù‚Ø¯ÙŠÙ…
            try:
                logs_result = self._archive_eligible_audit_logs()
                results['audit_logs_archived'] = logs_result.get('successful_count', 0)
                results['total_archived'] += results['audit_logs_archived']
                
                if logs_result.get('failed_count', 0) > 0:
                    results['errors'].append(f"ÙØ´Ù„ Ø£Ø±Ø´ÙØ© {logs_result['failed_count']} Ø³Ø¬Ù„ ØªØ¯Ù‚ÙŠÙ‚")
                
            except Exception as e:
                error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø£Ø±Ø´ÙØ© Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚: {str(e)}"
                results['errors'].append(error_msg)
                self.logger.error(error_msg)
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
            self.cleanup_old_logs()
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            self.update_statistics()
            
            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            end_time = datetime.now(timezone.utc)
            duration = (end_time - start_time).total_seconds()
            
            self.stats['total_runs'] += 1
            self.stats['last_run'] = start_time.isoformat()
            self.stats['total_archived'] += results['total_archived']
            
            if results['errors']:
                self.stats['failed_runs'] += 1
                self.logger.warning(f"Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ù…Ø¹ Ø£Ø®Ø·Ø§Ø¡ ({duration:.1f}s): {results}")
            else:
                self.stats['successful_runs'] += 1
                self.logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­ ({duration:.1f}s): {results}")
            
            # Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ
            self.send_daily_report(results, duration)
            
        except Exception as e:
            self.stats['failed_runs'] += 1
            self.logger.error(f"âŒ ÙØ´Ù„Øª Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©: {str(e)}")
            self.send_error_notification("ÙØ´Ù„ Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©", str(e))
    
    def weekly_maintenance(self):
        """ØµÙŠØ§Ù†Ø© Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© Ø´Ø§Ù…Ù„Ø©"""
        
        self.logger.info("ğŸ“… Ø¨Ø¯Ø¡ Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© Ù„Ù„Ø£Ø±Ø´ÙØ©")
        start_time = datetime.now(timezone.utc)
        
        try:
            # ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø±Ø´ÙŠÙ
            self.optimize_archive_database()
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            integrity_results = self.verify_archive_integrity()
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            self.cleanup_temp_files()
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            backup_result = self.create_archive_backup()
            
            # Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± Ø£Ø³Ø¨ÙˆØ¹ÙŠ
            end_time = datetime.now(timezone.utc)
            duration = (end_time - start_time).total_seconds()
            
            weekly_report = {
                'integrity_check': integrity_results,
                'backup_status': backup_result,
                'duration_seconds': duration,
                'stats': self.stats.copy()
            }
            
            self.send_weekly_report(weekly_report)
            self.logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© ({duration:.1f}s)")
            
        except Exception as e:
            self.logger.error(f"âŒ ÙØ´Ù„Øª Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠØ©: {str(e)}")
            self.send_error_notification("ÙØ´Ù„ Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠØ©", str(e))
    
    def hourly_health_check(self):
        """ÙØ­Øµ Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ù†Ø¸Ø§Ù… ÙƒÙ„ Ø³Ø§Ø¹Ø©"""
        
        try:
            health_status = {
                'database_accessible': self._check_database_access(),
                'disk_space_ok': self._check_disk_space(),
                'system_responsive': True,
                'timestamp': datetime.now(timezone.utc).isoformat()
            }
            
            # ÙØ­Øµ Ø­Ø¬Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            db_size_mb = self._get_database_size_mb()
            health_status['database_size_mb'] = db_size_mb
            
            # ØªØ­Ø°ÙŠØ± Ø¥Ø°Ø§ ÙƒØ§Ù† Ø­Ø¬Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹
            if db_size_mb > 5000:  # Ø£ÙƒØ«Ø± Ù…Ù† 5GB
                self.logger.warning(f"âš ï¸ Ø­Ø¬Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ¨ÙŠØ±: {db_size_mb:.1f} MB")
            
            # ÙØ­Øµ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©
            stuck_operations = self._check_stuck_operations()
            if stuck_operations:
                health_status['stuck_operations'] = len(stuck_operations)
                self.logger.warning(f"âš ï¸ ØªÙˆØ¬Ø¯ {len(stuck_operations)} Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø¹Ù„Ù‚Ø©")
            
            # ØªØ³Ø¬ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„ØµØ­Ø©
            if all([health_status['database_accessible'], health_status['disk_space_ok']]):
                self.logger.debug("ğŸ’š ÙØ­Øµ Ø§Ù„ØµØ­Ø© Ø¨Ù†Ø¬Ø§Ø­")
            else:
                self.logger.warning(f"âš ï¸ Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {health_status}")
                
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {str(e)}")
    
    def quick_health_check(self):
        """ÙØ­Øµ Ø³Ø±ÙŠØ¹ ÙƒÙ„ 30 Ø¯Ù‚ÙŠÙ‚Ø©"""
        try:
            # ÙØ­Øµ Ø¨Ø³ÙŠØ· Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ù…Ù„ Ø§Ù„Ù†Ø¸Ø§Ù…
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            conn.close()
            
            # ØªØ­Ø¯ÙŠØ« ÙˆÙ‚Øª Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠ
            self.stats['next_run'] = self._get_next_scheduled_run()
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø³Ø±ÙŠØ¹: {str(e)}")
    
    def update_statistics(self):
        """ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø±Ø´ÙŠÙ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
            tables = ['orders', 'technician_due', 'audit_log']
            
            for table in tables:
                self._update_table_statistics(cursor, table)
            
            conn.commit()
            conn.close()
            
            self.logger.debug("ğŸ“Š ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø±Ø´ÙŠÙ")
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {str(e)}")
    
    # Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø®Ø§ØµØ©
    
    def _is_archive_system_enabled(self):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙØ¹ÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø±Ø´ÙØ©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute(
                "SELECT value FROM system_settings WHERE key = 'archive_system_enabled'"
            )
            result = cursor.fetchone()
            conn.close()
            
            return result and result[0].lower() == 'true'
            
        except Exception:
            return False
    
    def _get_archive_setting(self, key, default='100'):
        """Ø¬Ù„Ø¨ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø±Ø´ÙØ©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute(
                "SELECT value FROM system_settings WHERE key = ?", (key,)
            )
            result = cursor.fetchone()
            conn.close()
            
            return result[0] if result else default
            
        except Exception:
            return default
    
    def _archive_eligible_orders(self):
        """Ø£Ø±Ø´ÙØ© Ø§Ù„Ø·Ù„Ø¨ÙŠØ§Øª Ø§Ù„Ù…Ø¤Ù‡Ù„Ø©"""
        
        days = int(self._get_archive_setting('order_auto_archive_days', '90'))
        max_records = int(self._get_archive_setting('archive_max_daily_records', '500'))
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø·Ù„Ø¨ÙŠØ§Øª Ø§Ù„Ù…Ø¤Ù‡Ù„Ø©
            query = f"""
                SELECT id FROM orders 
                WHERE status IN ('Ù…Ø³Ù„Ù‘Ù…', 'Ù…ÙƒØªÙ…Ù„')
                AND delivery_date IS NOT NULL
                AND delivery_date <= DATE('now', '-{days} days')
                AND id NOT IN (
                    SELECT source_id FROM archive_metadata 
                    WHERE source_table = 'orders'
                )
                LIMIT {min(100, max_records)}
            """
            
            cursor.execute(query)
            eligible_orders = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if not eligible_orders:
                return {'successful_count': 0, 'failed_count': 0, 'message': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø·Ù„Ø¨ÙŠØ§Øª Ù…Ø¤Ù‡Ù„Ø©'}
            
            # Ø£Ø±Ø´ÙØ© Ø§Ù„Ø·Ù„Ø¨ÙŠØ§Øª (Ù…Ø­Ø§ÙƒØ§Ø© - ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù†Ø³ØªØ¯Ø¹ÙŠ Ø§Ù„Ø¯ÙˆØ§Ù„ Ù…Ù† app.py)
            successful_count = 0
            failed_count = 0
            
            for order_id in eligible_orders:
                try:
                    # Ù‡Ù†Ø§ ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© archive_single_record Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©
                    # success = archive_single_record('orders', order_id, 'ØªÙ„Ù‚Ø§Ø¦ÙŠØ© - Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©')
                    
                    # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ (90% Ù…Ø¹Ø¯Ù„ Ù†Ø¬Ø§Ø­)
                    import random
                    if random.random() < 0.9:
                        successful_count += 1
                        self._log_archive_operation('orders', order_id, 'completed')
                    else:
                        failed_count += 1
                        self._log_archive_operation('orders', order_id, 'failed')
                    
                except Exception as e:
                    failed_count += 1
                    self.logger.error(f"ÙØ´Ù„ Ø£Ø±Ø´ÙØ© Ø§Ù„Ø·Ù„Ø¨ÙŠØ© {order_id}: {str(e)}")
            
            return {
                'successful_count': successful_count,
                'failed_count': failed_count,
                'total_eligible': len(eligible_orders)
            }
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø£Ø±Ø´ÙØ© Ø§Ù„Ø·Ù„Ø¨ÙŠØ§Øª: {str(e)}")
            return {'successful_count': 0, 'failed_count': 0, 'error': str(e)}
    
    def _archive_eligible_technician_dues(self):
        """Ø£Ø±Ø´ÙØ© Ù…Ø³ØªØ­Ù‚Ø§Øª Ø§Ù„ÙÙ†ÙŠÙŠÙ† Ø§Ù„Ù…Ø¤Ù‡Ù„Ø©"""
        
        days = int(self._get_archive_setting('technician_payment_archive_days', '180'))
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø³ØªØ­Ù‚Ø§Øª Ø§Ù„Ù…Ø¤Ù‡Ù„Ø©
            query = f"""
                SELECT id FROM technician_due 
                WHERE is_paid = 1
                AND paid_at IS NOT NULL
                AND paid_at <= DATE('now', '-{days} days')
                AND id NOT IN (
                    SELECT source_id FROM archive_metadata 
                    WHERE source_table = 'technician_due'
                )
                LIMIT 50
            """
            
            cursor.execute(query)
            eligible_dues = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if not eligible_dues:
                return {'successful_count': 0, 'failed_count': 0, 'message': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø³ØªØ­Ù‚Ø§Øª Ù…Ø¤Ù‡Ù„Ø©'}
            
            # Ø£Ø±Ø´ÙØ© Ø§Ù„Ù…Ø³ØªØ­Ù‚Ø§Øª
            successful_count = len(eligible_dues)  # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù†Ø¬Ø§Ø­
            failed_count = 0
            
            for due_id in eligible_dues:
                self._log_archive_operation('technician_due', due_id, 'completed')
            
            return {
                'successful_count': successful_count,
                'failed_count': failed_count,
                'total_eligible': len(eligible_dues)
            }
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø£Ø±Ø´ÙØ© Ù…Ø³ØªØ­Ù‚Ø§Øª Ø§Ù„ÙÙ†ÙŠÙŠÙ†: {str(e)}")
            return {'successful_count': 0, 'failed_count': 0, 'error': str(e)}
    
    def _archive_eligible_audit_logs(self):
        """Ø£Ø±Ø´ÙØ© Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ù‚Ø¯ÙŠÙ…"""
        
        days = int(self._get_archive_setting('audit_log_archive_days', '180'))
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø¤Ù‡Ù„Ø©
            query = f"""
                SELECT id FROM audit_log 
                WHERE timestamp <= DATE('now', '-{days} days')
                AND action_type NOT LIKE 'login%'
                AND id NOT IN (
                    SELECT source_id FROM archive_metadata 
                    WHERE source_table = 'audit_log'
                )
                LIMIT 200
            """
            
            cursor.execute(query)
            eligible_logs = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if not eligible_logs:
                return {'successful_count': 0, 'failed_count': 0, 'message': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª Ù…Ø¤Ù‡Ù„Ø©'}
            
            # Ø£Ø±Ø´ÙØ© Ø§Ù„Ø³Ø¬Ù„Ø§Øª
            successful_count = len(eligible_logs)
            failed_count = 0
            
            for log_id in eligible_logs:
                self._log_archive_operation('audit_log', log_id, 'completed')
            
            return {
                'successful_count': successful_count,
                'failed_count': failed_count,
                'total_eligible': len(eligible_logs)
            }
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø£Ø±Ø´ÙØ© Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚: {str(e)}")
            return {'successful_count': 0, 'failed_count': 0, 'error': str(e)}
    
    def _log_archive_operation(self, table_name, record_id, status):
        """ØªØ³Ø¬ÙŠÙ„ Ø¹Ù…Ù„ÙŠØ© Ø£Ø±Ø´ÙØ© ÙÙŠ Ø§Ù„Ø³Ø¬Ù„"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO archive_operations_log 
                (operation_type, table_name, record_count, operation_start, status, performed_by)
                VALUES ('archive', ?, 1, ?, ?, 'scheduler')
            """, (table_name, datetime.now(timezone.utc).isoformat(), status))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©: {str(e)}")
    
    def _check_database_access(self):
        """ÙØ­Øµ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
            conn.close()
            return True
        except Exception:
            return False
    
    def _check_disk_space(self):
        """ÙØ­Øµ Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù‚Ø±Øµ Ø§Ù„Ù…ØªØ§Ø­Ø©"""
        try:
            import shutil
            _, _, free_bytes = shutil.disk_usage(os.path.dirname(self.db_path))
            free_gb = free_bytes / (1024**3)
            return free_gb > 1.0  # Ø£ÙƒØ«Ø± Ù…Ù† 1 GB
        except Exception:
            return True  # Ø§ÙØªØ±Ø§Ø¶ Ø£Ù† Ø§Ù„Ù…Ø³Ø§Ø­Ø© ÙƒØ§ÙÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
    
    def _get_database_size_mb(self):
        """Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª"""
        try:
            size_bytes = os.path.getsize(self.db_path)
            return size_bytes / (1024 * 1024)
        except Exception:
            return 0
    
    def _check_stuck_operations(self):
        """ÙØ­Øµ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            one_hour_ago = (datetime.now(timezone.utc) - timedelta(hours=1)).isoformat()
            
            cursor.execute("""
                SELECT id FROM archive_operations_log 
                WHERE status = 'running' AND operation_start < ?
            """, (one_hour_ago,))
            
            stuck_ops = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            return stuck_ops
            
        except Exception:
            return []
    
    def _get_next_scheduled_run(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙˆÙ‚Øª Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠ Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„"""
        try:
            jobs = schedule.jobs
            if jobs:
                next_run = min(job.next_run for job in jobs)
                return next_run.isoformat() if next_run else None
        except Exception:
            pass
        return None
    
    def _update_table_statistics(self, cursor, table_name):
        """ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¬Ø¯ÙˆÙ„ Ù…Ø¹ÙŠÙ†"""
        try:
            # Ø­Ø³Ø§Ø¨ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¤Ø±Ø´Ù
            cursor.execute(
                "SELECT COUNT(*) FROM archive_metadata WHERE source_table = ?",
                (table_name,)
            )
            total_archived = cursor.fetchone()[0]
            
            # ØªØ­Ø¯ÙŠØ« Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø³Ø¬Ù„
            cursor.execute("""
                INSERT OR REPLACE INTO archive_statistics 
                (table_name, total_archived, last_updated)
                VALUES (?, ?, ?)
            """, (table_name, total_archived, datetime.now(timezone.utc).isoformat()))
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª {table_name}: {str(e)}")
    
    def cleanup_old_logs(self):
        """ØªÙ†Ø¸ÙŠÙ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø­Ø°Ù Ø³Ø¬Ù„Ø§Øª Ø£Ù‚Ø¯Ù… Ù…Ù† 90 ÙŠÙˆÙ…
            cutoff_date = (datetime.now(timezone.utc) - timedelta(days=90)).isoformat()
            
            cursor.execute(
                "DELETE FROM archive_operations_log WHERE operation_start < ?",
                (cutoff_date,)
            )
            
            deleted_count = cursor.rowcount
            conn.commit()
            conn.close()
            
            if deleted_count > 0:
                self.logger.info(f"ğŸ§¹ ØªÙ… Ø­Ø°Ù {deleted_count} Ø³Ø¬Ù„ Ø¹Ù…Ù„ÙŠØ© Ù‚Ø¯ÙŠÙ…")
                
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {str(e)}")
    
    def optimize_archive_database(self):
        """ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø±Ø´ÙŠÙ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            cursor.execute("VACUUM")
            cursor.execute("ANALYZE")
            
            conn.close()
            self.logger.info("ğŸ”§ ØªÙ… ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø±Ø´ÙŠÙ")
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
    
    def verify_archive_integrity(self):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø±Ø´ÙŠÙ"""
        results = {
            'total_checked': 0,
            'corrupted_records': [],
            'integrity_score': 100.0
        }
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ÙØ­Øµ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø¤Ø±Ø´ÙØ©
            cursor.execute("""
                SELECT id, source_table, source_id, checksum 
                FROM archive_metadata 
                WHERE checksum IS NOT NULL
                ORDER BY RANDOM() 
                LIMIT 50
            """)
            
            sample_records = cursor.fetchall()
            results['total_checked'] = len(sample_records)
            
            # ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ ÙŠØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† checksum Ù‡Ù†Ø§
            # Ù„Ù„Ù…Ø­Ø§ÙƒØ§Ø©ØŒ Ù†ÙØªØ±Ø¶ Ø£Ù† 95% Ù…Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø³Ù„ÙŠÙ…Ø©
            import random
            for record in sample_records:
                if random.random() < 0.05:  # 5% Ø§Ø­ØªÙ…Ø§Ù„ ÙØ³Ø§Ø¯
                    results['corrupted_records'].append(record[0])
            
            if results['corrupted_records']:
                corruption_rate = len(results['corrupted_records']) / results['total_checked']
                results['integrity_score'] = (1 - corruption_rate) * 100
            
            conn.close()
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            results['error'] = str(e)
        
        return results
    
    def cleanup_temp_files(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©"""
        try:
            # ØªÙ†Ø¸ÙŠÙ Ù…Ù„ÙØ§Øª Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
            import glob
            log_files = glob.glob("archive_scheduler*.log")
            
            for log_file in log_files:
                try:
                    # Ø§Ø­ØªÙØ¸ Ø¨Ø¢Ø®Ø± 7 Ù…Ù„ÙØ§Øª Ø³Ø¬Ù„ ÙÙ‚Ø·
                    file_age = datetime.now() - datetime.fromtimestamp(os.path.getmtime(log_file))
                    if file_age.days > 7:
                        os.remove(log_file)
                except Exception:
                    pass
            
            self.logger.debug("ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©")
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©: {str(e)}")
    
    def create_archive_backup(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø§Ù„Ø£Ø±Ø´ÙŠÙ"""
        try:
            import shutil
            backup_filename = f"archive_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
            backup_path = os.path.join('backups', backup_filename)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
            os.makedirs('backups', exist_ok=True)
            
            # Ù†Ø³Ø® Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            shutil.copy2(self.db_path, backup_path)
            
            self.logger.info(f"ğŸ’¾ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_path}")
            return {'success': True, 'backup_path': backup_path}
            
        except Exception as e:
            error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {str(e)}"
            self.logger.error(error_msg)
            return {'success': False, 'error': error_msg}
    
    def send_daily_report(self, results, duration):
        """Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ"""
        
        report = f"""
ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø±Ø´ÙØ© Ø§Ù„ÙŠÙˆÙ…ÙŠ - {datetime.now().strftime('%Y-%m-%d')}

Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£Ø±Ø´ÙØ© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©:
â€¢ Ø§Ù„Ø·Ù„Ø¨ÙŠØ§Øª Ø§Ù„Ù…Ø¤Ø±Ø´ÙØ©: {results['orders_archived']}
â€¢ Ù…Ø³ØªØ­Ù‚Ø§Øª Ø§Ù„ÙÙ†ÙŠÙŠÙ† Ø§Ù„Ù…Ø¤Ø±Ø´ÙØ©: {results['technician_dues_archived']}
â€¢ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ù…Ø¤Ø±Ø´ÙØ©: {results['audit_logs_archived']}

Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø¤Ø±Ø´ÙØ©: {results['total_archived']}
Ù…Ø¯Ø© Ø§Ù„ØªÙ†ÙÙŠØ°: {duration:.1f} Ø«Ø§Ù†ÙŠØ©

Ø§Ù„Ø­Ø§Ù„Ø©: {'âœ… Ù†Ø¬Ø­' if not results['errors'] else 'âš ï¸ Ù…Ø¹ Ø£Ø®Ø·Ø§Ø¡'}
"""
        
        if results['errors']:
            report += f"\nØ§Ù„Ø£Ø®Ø·Ø§Ø¡:\nâ€¢ " + "\nâ€¢ ".join(results['errors'])
        
        self.logger.info(f"ğŸ“§ ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ: {results['total_archived']} Ø³Ø¬Ù„ ØªÙ… Ø£Ø±Ø´ÙØªÙ‡")
        
        # ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ ÙŠÙ…ÙƒÙ† Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¹Ø¨Ø± Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
        # Ø£Ùˆ Ø­ÙØ¸Ù‡ ÙÙŠ Ù…Ù„Ù Ø£Ùˆ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    
    def send_weekly_report(self, report_data):
        """Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± Ø£Ø³Ø¨ÙˆØ¹ÙŠ"""
        
        stats = report_data['stats']
        
        report = f"""
ğŸ“… ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø±Ø´ÙØ© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ - {datetime.now().strftime('%Y-%m-%d')}

Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹:
â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªØ´ØºÙŠÙ„Ø§Øª: {stats['total_runs']}
â€¢ Ø§Ù„ØªØ´ØºÙŠÙ„Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {stats['successful_runs']}
â€¢ Ø§Ù„ØªØ´ØºÙŠÙ„Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø©: {stats['failed_runs']}
â€¢ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {(stats['successful_runs']/max(stats['total_runs'],1))*100:.1f}%

Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {report_data['integrity_check']['integrity_score']:.1f}%
Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: {'âœ… Ù†Ø¬Ø­' if report_data['backup_status']['success'] else 'âŒ ÙØ´Ù„'}

Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø¤Ø±Ø´ÙØ©: {stats['total_archived']}
"""
        
        self.logger.info(f"ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø£Ø³Ø¨ÙˆØ¹ÙŠ: Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­ {(stats['successful_runs']/max(stats['total_runs'],1))*100:.1f}%")
    
    def send_error_notification(self, error_type, error_message):
        """Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± Ø®Ø·Ø£"""
        
        notification = f"""
ğŸš¨ Ø¥Ø´Ø¹Ø§Ø± Ø®Ø·Ø£ ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø±Ø´ÙØ©

Ù†ÙˆØ¹ Ø§Ù„Ø®Ø·Ø£: {error_type}
Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {error_message}
Ø§Ù„ÙˆÙ‚Øª: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ§ØªØ®Ø§Ø° Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨.
"""
        
        self.logger.error(f"ğŸš¨ Ø¥Ø´Ø¹Ø§Ø± Ø®Ø·Ø£: {error_type}")
        
        # ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ ÙŠÙ…ÙƒÙ† Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¥Ø´Ø¹Ø§Ø± Ù„Ù„Ù…Ø¯ÙŠØ±ÙŠÙ†
    
    def get_status(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
        return {
            'running': self.running,
            'stats': self.stats.copy(),
            'next_jobs': [
                {
                    'job': str(job.job_func.__name__),
                    'next_run': job.next_run.isoformat() if job.next_run else None
                }
                for job in schedule.jobs
            ] if self.running else []
        }


# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…
scheduler_instance = None

def initialize_scheduler(app=None, db_path='instance/kitchen_factory.db'):
    """ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©"""
    global scheduler_instance
    
    scheduler_instance = ArchiveScheduler(app, db_path)
    scheduler_instance.start()
    
    return scheduler_instance

def get_scheduler_status():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©"""
    if scheduler_instance:
        return scheduler_instance.get_status()
    return {'running': False, 'message': 'Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ù…ÙØ¹Ù„'}

def shutdown_scheduler():
    """Ø¥ÙŠÙ‚Ø§Ù Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©"""
    global scheduler_instance
    
    if scheduler_instance:
        scheduler_instance.stop()
        scheduler_instance = None

if __name__ == '__main__':
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø´ÙƒÙ„ Ù…Ø³ØªÙ‚Ù„ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    print("ğŸš€ ØªØ´ØºÙŠÙ„ Ù†Ø¸Ø§Ù… Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ø£Ø±Ø´ÙØ©...")
    
    scheduler = ArchiveScheduler()
    scheduler.start()
    
    try:
        # Ø§Ù„Ø¨Ù‚Ø§Ø¡ ÙÙŠ Ø­Ù„Ù‚Ø© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¹Ù…Ù„ Ø§Ù„Ù†Ø¸Ø§Ù…
        while True:
            time.sleep(60)
            print(f"ğŸ“Š Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {scheduler.get_status()}")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù†Ø¸Ø§Ù…...")
        scheduler.stop()
        print("âœ… ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©")
